{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "This note book outlines analysing the structure of text and associated patterns whilst laying the foundation of a chatbot that can read in and analyse a PDF. Of which you can query and discuss the content using vector search. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SETTING UP THE ENVIRONMENT #####\n",
    "\n",
    "# %pip install ipykernel -U --user --force-reinstall\n",
    "# %pip install --upgrade pip\n",
    "# %pip install diversity\n",
    "# %pip install spacy\n",
    "# %pip install nltk\n",
    "# %pip install --upgrade packaging\n",
    "# !python3 -m spacy download en\n",
    "\n",
    "# import nltk\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTING DUMMY ESSAY ####\n",
    "\n",
    "with open('example_essay.txt', 'r') as file:\n",
    "    essay_text = file.read()\n",
    "    \n",
    "split_text = essay_text.split('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Syntactic Templates from a generated essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring all pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9120/9120 [00:00<00:00, 39226.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.216 0.052 2.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from diversity import compression_ratio, homogenization_score, ngram_diversity_score, extract_patterns\n",
    "\n",
    "cr = compression_ratio(split_text, 'gzip')\n",
    "hs = homogenization_score(split_text, 'rougel')\n",
    "# hs = homogenization_score(data_example, 'bertscore') \n",
    "nds = ngram_diversity_score(split_text, 4)\n",
    "\n",
    "print(cr, hs, nds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN JJ NNS IN NN': {'on massive amounts of text',\n",
       "  'on relevant parts of input',\n",
       "  'over long sequences of text'},\n",
       " 'HYPH NN NNP : :': {'- Thought Prompting : -', '- shot Prompting : -'},\n",
       " 'NNP : : VBZ DT': {'Prompting : - Assigns a',\n",
       "  'Prompting : - Provides a',\n",
       "  'Prompting : - Requires no'},\n",
       " 'JJ NNS CD . NN': set(),\n",
       " '. NNP NNP : :': set(),\n",
       " 'JJ NN HYPH VBN NNS': {'simple rule - based systems',\n",
       "  'various language - related tasks'},\n",
       " 'NNP -LRB- NNP NNP JJ': {'GPT ( Generative Pre -'},\n",
       " '-LRB- NNP NNP JJ VBN': {'( Generative Pre - trained'},\n",
       " 'NNP NNP JJ VBN NNP': {'Generative Pre - trained Transformer'},\n",
       " 'NNP JJ VBN NNP -RRB-': {'Pre - trained Transformer )'},\n",
       " 'NN NNP : : VBZ': {'shot Prompting : - Provides',\n",
       "  'shot Prompting : - Requires'},\n",
       " 'VBZ DT NN TO VB': {'Allows the model to focus', 'asks the model to perform'},\n",
       " ': : VBZ DT JJ': {': - Assigns a specific', ': - Provides a few'},\n",
       " 'CC JJ NNS CD .': {'and residual connections 3 .', 'or logical problems 4 .'},\n",
       " 'NNS CD . NN HYPH': set(),\n",
       " 'CD . NN HYPH VBN': set(),\n",
       " '. NN HYPH VBN NNP': set(),\n",
       " 'NN HYPH VBN NNP :': {'Instruction - based Prompting :',\n",
       "  'Role - based Prompting :'},\n",
       " 'HYPH VBN NNP : :': {'- based Prompting : -'},\n",
       " 'VBN NNP : : VBZ': {'based Prompting : - Assigns',\n",
       "  'based Prompting : - Provides'},\n",
       " ': NNP VB JJ NN': {'- Helps maintain consistent output',\n",
       "  '- Helps maintain consistent perspective'},\n",
       " 'NNP : : VBZ JJ': {'Layer : - Processes raw', 'Prompting : - Provides clear'},\n",
       " 'CD . NNP NNP :': set(),\n",
       " 'NNS : MD VB JJ': {'attempts - May involve social',\n",
       "  'safeguards - Can include prompt'},\n",
       " ': MD VB JJ NN': {'- Can include prompt injection',\n",
       "  '- May involve social engineering'},\n",
       " 'VB JJ NN NNS :': {'implement various security measures :',\n",
       "  'involve social engineering techniques -'},\n",
       " 'NNP NNP : : VBZ': {'Input Layer : - Processes',\n",
       "  'Output Layer : - Generates'},\n",
       " 'JJ NNS IN NN HYPH': {'Multiple layers of self -',\n",
       "  'relevant parts of input -'},\n",
       " 'NN NNS : JJR NN': {'attention heads - Larger context',\n",
       "  'transformer blocks - Wider attention'},\n",
       " 'IN JJ NN NNS .': {'for legitimate use cases .',\n",
       "  'for various language tasks .'},\n",
       " 'NN NN HYPH JJ NN': {'Input sanitization - Content filtering',\n",
       "  'Response validation - Robust system'},\n",
       " 'NNP NNP NNPS CC JJ': {'Artificial Intelligence Models and Large'},\n",
       " 'NNP NNPS CC JJ NNP': {'Intelligence Models and Large Language'},\n",
       " 'NNPS CC JJ NNP NNS': {'Models and Large Language Models'},\n",
       " 'CC JJ NNP NNS :': {'and Large Language Models :'},\n",
       " 'JJ NNP NNS : DT': {'Large Language Models : An'},\n",
       " 'NNP NNS : DT NNP': {'Language Models : An Overview'},\n",
       " 'NNS : DT NNP NNP': {'Models : An Overview Artificial'},\n",
       " ': DT NNP NNP NNP': {': An Overview Artificial Intelligence'},\n",
       " 'DT NNP NNP NNP -LRB-': {'An Overview Artificial Intelligence ('},\n",
       " 'NNP NNP NNP -LRB- NNP': {'Overview Artificial Intelligence ( AI'},\n",
       " 'NNP NNP -LRB- NNP -RRB-': {'Artificial Intelligence ( AI )'},\n",
       " 'NNP -LRB- NNP -RRB- NNS': {'Intelligence ( AI ) Models'},\n",
       " '-LRB- NNP -RRB- NNS VBP': {'( AI ) Models are'},\n",
       " 'NNP -RRB- NNS VBP JJ': {'AI ) Models are computational'},\n",
       " '-RRB- NNS VBP JJ NNS': {') Models are computational systems'},\n",
       " 'NNS VBP JJ NNS VBN': {'Models are computational systems designed'},\n",
       " 'VBP JJ NNS VBN TO': {'are computational systems designed to'},\n",
       " 'JJ NNS VBN TO VB': {'computational systems designed to simulate'},\n",
       " 'NNS VBN TO VB JJ': {'systems designed to simulate human'},\n",
       " 'VBN TO VB JJ NN': {'designed to simulate human intelligence'},\n",
       " 'TO VB JJ NN CC': {'to simulate human intelligence and'},\n",
       " 'VB JJ NN CC VB': {'simulate human intelligence and perform'},\n",
       " 'JJ NN CC VB NNS': {'human intelligence and perform tasks'},\n",
       " 'NN CC VB NNS WDT': {'intelligence and perform tasks that'},\n",
       " 'CC VB NNS WDT RB': {'and perform tasks that typically'},\n",
       " 'VB NNS WDT RB VBP': {'perform tasks that typically require'},\n",
       " 'NNS WDT RB VBP JJ': {'tasks that typically require human'},\n",
       " 'WDT RB VBP JJ JJ': {'that typically require human cognitive'},\n",
       " 'RB VBP JJ JJ NNS': {'typically require human cognitive abilities'},\n",
       " 'VBP JJ JJ NNS .': {'require human cognitive abilities .'},\n",
       " 'JJ JJ NNS . DT': set(),\n",
       " 'JJ NNS . DT NNS': set(),\n",
       " 'NNS . DT NNS MD': set(),\n",
       " '. DT NNS MD VB': set(),\n",
       " 'DT NNS MD VB IN': {'These models can range from'},\n",
       " 'NNS MD VB IN JJ': {'models can range from simple'},\n",
       " 'MD VB IN JJ NN': {'can range from simple rule'},\n",
       " 'VB IN JJ NN HYPH': {'range from simple rule -'},\n",
       " 'IN JJ NN HYPH VBN': {'from simple rule - based'},\n",
       " 'NN HYPH VBN NNS IN': {'rule - based systems to'},\n",
       " 'HYPH VBN NNS IN JJ': {'- based systems to complex'},\n",
       " 'VBN NNS IN JJ JJ': {'based systems to complex neural'},\n",
       " 'NNS IN JJ JJ NNS': {'systems to complex neural networks'},\n",
       " 'IN JJ JJ NNS JJ': {'to complex neural networks capable'},\n",
       " 'JJ JJ NNS JJ IN': {'complex neural networks capable of'},\n",
       " 'JJ NNS JJ IN VBG': {'neural networks capable of learning'},\n",
       " 'NNS JJ IN VBG IN': {'networks capable of learning from'},\n",
       " 'JJ IN VBG IN JJ': {'capable of learning from vast'},\n",
       " 'IN VBG IN JJ NNS': {'of learning from vast amounts'},\n",
       " 'VBG IN JJ NNS IN': {'learning from vast amounts of'},\n",
       " 'IN JJ NNS IN NNS': {'from vast amounts of data'},\n",
       " 'JJ NNS IN NNS .': {'vast amounts of data .'},\n",
       " 'NNS IN NNS . NNP': set(),\n",
       " 'IN NNS . NNP NNS': set(),\n",
       " 'NNS . NNP NNS MD': set(),\n",
       " '. NNP NNS MD VB': set(),\n",
       " 'NNP NNS MD VB VBN': {'AI models can be classified'},\n",
       " 'NNS MD VB VBN IN': {'models can be classified into'},\n",
       " 'MD VB VBN IN JJ': {'can be classified into various'},\n",
       " 'VB VBN IN JJ NNS': {'be classified into various categories'},\n",
       " 'VBN IN JJ NNS ,': {'classified into various categories ,'},\n",
       " 'IN JJ NNS , VBG': {'into various categories , including'},\n",
       " 'JJ NNS , VBG JJ': {'various categories , including supervised'},\n",
       " 'NNS , VBG JJ NN': {'categories , including supervised learning'},\n",
       " ', VBG JJ NN ,': {', including supervised learning ,'},\n",
       " 'VBG JJ NN , JJ': {'including supervised learning , unsupervised'},\n",
       " 'JJ NN , JJ NN': {'supervised learning , unsupervised learning'},\n",
       " 'NN , JJ NN ,': {'learning , unsupervised learning ,'},\n",
       " ', JJ NN , CC': {', unsupervised learning , and'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5 \n",
    "top_n = 100\n",
    "patterns = extract_patterns(split_text, n, top_n)\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN IN DT JJ NN': {'definition of a good developer',\n",
       "  'democracy in the Western world',\n",
       "  'indicator of a good design',\n",
       "  'industry like no other shakedown',\n",
       "  'model as the gold standard',\n",
       "  'one with the architectural fit',\n",
       "  'tech on a worldwide scale',\n",
       "  'wave of the same category'},\n",
       " '. DT JJ NN IN': set(),\n",
       " 'DT JJ NN IN DT': {'The 2nd wave of the',\n",
       "  'The sole indicator of a',\n",
       "  'The standard definition of a',\n",
       "  'an auxiliary outlet in the'},\n",
       " 'JJ NN IN DT JJ': {'2nd wave of the same',\n",
       "  'big tech on a worldwide',\n",
       "  'sole indicator of a good',\n",
       "  'standard definition of a good'},\n",
       " 'DT JJ NN IN NN': {'The bad thing about design',\n",
       "  'a dominant point in management',\n",
       "  'the direct line of fire',\n",
       "  'the gold standard of app',\n",
       "  'the high ground around privacy'},\n",
       " 'DT JJ JJ NN .': {'a good mobile developer .', 'a great mobile developer .'},\n",
       " 'NNP , NNP , CC': {'Apple , Android , and',\n",
       "  'C++ , Java , and',\n",
       "  'Cordova , Xamarin , and'},\n",
       " 'DT NNS IN DT NN': {'the buzzwords on every tech',\n",
       "  'the results of an industry',\n",
       "  'the workflows of the hardware'},\n",
       " 'DT JJ NN IN JJ': {'a sizable app with smooth',\n",
       "  'the first domino of mobile',\n",
       "  'the true power of mobile'},\n",
       " 'IN DT JJ NN ,': {'On a parallel track ,',\n",
       "  'by the top tier ,',\n",
       "  'in the long run ,'},\n",
       " 'NN . NN NN VBD': set(),\n",
       " 'NN -LRB- NNP , NNP': {'platform ( Mac , Vision',\n",
       "  'provider ( GCP , Google',\n",
       "  'stuff ( C++ , Java'},\n",
       " 'IN DT JJ NN .': {'from every other department .',\n",
       "  'like no other shakedown .',\n",
       "  'on a worldwide scale .'},\n",
       " 'VBZ DT JJ JJ NN': {'defines a good mobile developer',\n",
       "  'makes a great mobile app',\n",
       "  'makes a great mobile developer'},\n",
       " 'NN . DT JJ NN': set(),\n",
       " 'IN DT JJ NN -LRB-': {'of a good developer (', 'of the same platform ('},\n",
       " 'CC EX VBP JJR .': {'But there ’s more .', 'but there ’s more .'},\n",
       " 'IN DT JJ HYPH NN': {'As a long - time', 'of the human - computer'},\n",
       " 'NN , PRP VBP JJ': {'developer , I am eager',\n",
       "  'perspective , they are simple'},\n",
       " 'JJ JJ JJ NNS .': {'cross - platform ecosystems .',\n",
       "  'mid - level developers .'},\n",
       " '. RB , DT JJ': set(),\n",
       " 'JJ NNS IN DT NN': {'obvious shortcomings of the approach',\n",
       "  'recent signals from the industry'},\n",
       " 'IN PRP$ NN NN .': {'from my LinkedIn search .', 'of their creation love ?'},\n",
       " 'NN . EX VBZ RB': set(),\n",
       " 'RB DT JJ JJ NN': {'also a prominent worldwide employer',\n",
       "  'also an interesting Reddit thread'},\n",
       " 'DT NN IN JJ NN': {'The number of mobile dev',\n",
       "  'the discourse on mobile development'},\n",
       " 'IN JJ CC JJ NNS': {'in online + offline forums',\n",
       "  'in small and medium firms'},\n",
       " 'JJ NN VBD DT JJS': {'Indie devs suffered the most',\n",
       "  'mobile development was the coolest'},\n",
       " 'NNS : NNP CC NNP': {'platforms : Apple and Google',\n",
       "  'platforms : iOS and Android'},\n",
       " ': NNP CC NNP .': {': Apple and Google .', ': iOS and Android .'},\n",
       " 'NN , DT NN VBD': {'decade , the battle kept',\n",
       "  'design , this battle remained'},\n",
       " 'NNS IN DT NN NN': {'buzzwords on every tech manager',\n",
       "  'workflows of the hardware integration'},\n",
       " 'NNP CC NNP . NNP': set(),\n",
       " 'DT JJS NN IN DT': {'the biggest component of the',\n",
       "  'the biggest victim of this'},\n",
       " 'IN NNP CC NNP ,': {'by Facebook and Google ,', 'with UX and UI ,'},\n",
       " 'NNS IN JJ NNS .': {'developers to big clients .',\n",
       "  'risks in mobile deliveries .'},\n",
       " 'JJ NN IN DT NN': {'auxiliary outlet in the company',\n",
       "  'platform chorus from the bottom'},\n",
       " ', NNP VBD TO VB': {', Apple began to hail', ', Devs had to learn'},\n",
       " 'NN IN DT NN .': {'perception of the industry .', 'victim of this move .'},\n",
       " 'IN DT JJ NN VBZ': {'in the Western world is', 'of a good design is'},\n",
       " 'JJ NNS IN JJ NN': {'governmental attacks upon big tech',\n",
       "  'simple boxes with identical plug'},\n",
       " 'IN JJ NN IN DT': {'While successful integration of all',\n",
       "  'upon big tech on a'},\n",
       " 'IN DT JJ NN IN': {'as the gold standard of', 'in the direct line of'},\n",
       " '-LRB- NNP , NNP NN': {'( GCP , Google education', '( Mac , Vision pro'},\n",
       " 'VBD DT JJ NN IN': {'became a dominant point in',\n",
       "  'took the high ground around'},\n",
       " 'VBG DT NN IN NN': {'becoming the master of hardware',\n",
       "  'giving the power of ad'},\n",
       " 'NNP VBD TO VB PRP$': {'Apple began to hail its',\n",
       "  'Apple began to improve its'},\n",
       " 'VBD TO VB PRP$ RB': {'began to hail its highly',\n",
       "  'began to improve its highly'},\n",
       " 'JJ NN NN IN DT': {'mobile development industry like no',\n",
       "  'touted subscription model as the'},\n",
       " 'NN NN IN DT JJ': {'development industry like no other',\n",
       "  'subscription model as the gold'},\n",
       " 'JJ NN IN NN NN': {'gold standard of app development',\n",
       "  'little differentiation from web development'},\n",
       " 'NN IN NN NN .': {'standard of app development .',\n",
       "  'support for subscription API .'},\n",
       " 'NNS , CC JJ NNS': {'fixes , and useless discussions',\n",
       "  'libraries , and reusable components'},\n",
       " 'JJ NN IN NN NNS': {'deft usage of smartphone sensors',\n",
       "  'dominant point in management discussions'},\n",
       " 'DT JJ NN TO VB': {'a good developer to begin',\n",
       "  'a serious contender to mainstream'},\n",
       " 'TO VB DT NN IN': {'to handle this shift in', 'to share the glory with'},\n",
       " 'DT JJ NN -LRB- ``': {'a good developer ( “'},\n",
       " 'JJ NN -LRB- `` NN': {'good developer ( “ designer'},\n",
       " 'NN , FW , NN': {'designer , coder , tester', 'program , coder , tester'},\n",
       " \", FW , NN ''\": {', coder , tester ”'},\n",
       " \"FW , NN '' -RRB-\": {'coder , tester ” )'},\n",
       " \", NN '' -RRB- VBZ\": {', tester ” ) does'},\n",
       " \"NN '' -RRB- VBZ RB\": {'tester ” ) does not'},\n",
       " \"'' -RRB- VBZ RB RB\": {'” ) does not fully'},\n",
       " '-RRB- VBZ RB RB VB': {') does not fully define'},\n",
       " 'VBZ RB RB VB DT': {'does not fully define a'},\n",
       " 'RB RB VB DT JJ': {'not fully define a good'},\n",
       " 'RB VB DT JJ JJ': {'fully define a good mobile'},\n",
       " 'VB DT JJ JJ NN': {'define a good mobile developer'},\n",
       " 'WP VBZ DT JJ JJ': {'What makes a great mobile'},\n",
       " 'DT JJ JJ NN VBZ': {'a great mobile app has',\n",
       "  'an indie mobile developer surprises'},\n",
       " 'NN IN NN NNS .': {'glory with data scientists .',\n",
       "  'usage of smartphone sensors .'},\n",
       " 'NNS . DT JJ NN': set(),\n",
       " 'VBZ TO VB DT JJ': {'continues to be an auxiliary', 'has to be a good'},\n",
       " 'TO VB DT JJ NN': {'to be a good developer', 'to be an auxiliary outlet'},\n",
       " 'NN IN NN VBZ IN': {'perception of greatness comes from',\n",
       "  'thing about design is that'},\n",
       " 'DT JJ NN VBZ IN': {'The only way is through', 'a good design is whether'},\n",
       " '. DT JJ JJ NN': set(),\n",
       " 'JJ NNS VBP DT NN': {'medium firms have no moat',\n",
       "  'sized LLMs become a reality'},\n",
       " 'JJ NN VBP TO VB': {'competent devs aim to multiply',\n",
       "  'mobile devs have to tread'},\n",
       " 'NNS IN DT JJ NN': {'Devices of the same platform',\n",
       "  'dollars from every other department'},\n",
       " 'VB TO VB DT NN': {'have to share the glory', 'want to buy a domain'},\n",
       " 'NNP NNS VBP VBN PRP$': {'Mobile Developers Have Lost Their'},\n",
       " 'NNS VBP VBN PRP$ NN': {'Developers Have Lost Their Glory'},\n",
       " 'VBP VBN PRP$ NN ,': {'Have Lost Their Glory ,'},\n",
       " 'VBN PRP$ NN , CC': {'Lost Their Glory , and'},\n",
       " 'PRP$ NN , CC RB': {'Their Glory , and Here'},\n",
       " 'NN , CC RB VBZ': {'Glory , and Here ’s'},\n",
       " ', CC RB VBZ WRB': {', and Here ’s Why'},\n",
       " 'CC RB VBZ WRB NNP': {'and Here ’s Why Pen'},\n",
       " 'RB VBZ WRB NNP NNP': {'Here ’s Why Pen Magnet'},\n",
       " 'VBZ WRB NNP NNP NNP': {'’s Why Pen Magnet Level'},\n",
       " 'WRB NNP NNP NNP RP': {'Why Pen Magnet Level Up'},\n",
       " 'NNP NNP NNP RP NNP': {'Pen Magnet Level Up Coding'},\n",
       " 'NNP NNP RP NNP NNP': {'Magnet Level Up Coding Pen'},\n",
       " 'NNP RP NNP NNP NNP': {'Level Up Coding Pen Magnet'},\n",
       " 'RP NNP NNP NNP NFP': {'Up Coding Pen Magnet ·'},\n",
       " 'NNP NNP NNP NFP NNP': {'Coding Pen Magnet · Follow'},\n",
       " 'NNP NNP NFP NNP VBN': {'Pen Magnet · Follow Published'},\n",
       " 'NNP NFP NNP VBN IN': {'Magnet · Follow Published in'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('human_essay.txt', 'r') as new_file:\n",
    "    text = new_file.read()\n",
    "    text_split_human = text.split('\\n')\n",
    "\n",
    "text_split_human\n",
    "patterns = extract_patterns(text_split_human, n, top_n)\n",
    "patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 patterns in human-written essay:\n",
      "NN IN DT JJ NN: 8 occurrences\n",
      "DT JJ NN IN NN: 5 occurrences\n",
      "DT JJ NN IN DT: 4 occurrences\n",
      "JJ NN IN DT JJ: 4 occurrences\n",
      "NNP , NNP , CC: 3 occurrences\n",
      "\n",
      "Top 5 patterns in example essay:\n",
      "IN JJ NNS IN NN: 3 occurrences\n",
      "NNP : : VBZ DT: 3 occurrences\n",
      "HYPH NN NNP : :: 2 occurrences\n",
      "JJ NN HYPH VBN NNS: 2 occurrences\n",
      "NN NNP : : VBZ: 2 occurrences\n"
     ]
    }
   ],
   "source": [
    "# Get patterns for both texts\n",
    "human_patterns = extract_patterns(text_split_human, n, top_n)\n",
    "example_patterns = extract_patterns(split_text, n, top_n)\n",
    "\n",
    "# Sort patterns by frequency and get top 5\n",
    "def get_top_5_patterns(patterns):\n",
    "    # Convert patterns dict to list of tuples (pattern, examples)\n",
    "    pattern_list = [(k, len(v)) for k,v in patterns.items() if len(v) > 0]\n",
    "    # Sort by frequency (count of examples) in descending order\n",
    "    pattern_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Return top 5 or all if less than 5\n",
    "    return pattern_list[:5]\n",
    "\n",
    "print(\"Top 5 patterns in human-written essay:\")\n",
    "for pattern, freq in get_top_5_patterns(human_patterns):\n",
    "    print(f\"{pattern}: {freq} occurrences\")\n",
    "\n",
    "print(\"\\nTop 5 patterns in example essay:\")\n",
    "for pattern, freq in get_top_5_patterns(example_patterns):\n",
    "    print(f\"{pattern}: {freq} occurrences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Pattern Differences Between Human and Example Essays\n",
    "\n",
    "The pattern analysis reveals interesting differences in writing style between the human-written and example essays:\n",
    "\n",
    "1. Pattern Frequency:\n",
    "- Human essay has higher pattern frequencies (8, 5, 4, 4, 3 occurrences)\n",
    "- Example essay has lower frequencies (3, 3, 2, 2, 2 occurrences)\n",
    "\n",
    "2. Pattern Types:\n",
    "- Human essay favors noun-preposition-adjective patterns (e.g. \"NN IN DT JJ NN\")\n",
    "- Example essay uses more technical/structured patterns with colons and hyphens\n",
    "\n",
    "3. Key Differences:\n",
    "- Human writing shows more natural language flow with descriptive phrases\n",
    "- Example essay has more formatted/templated structure typical of technical writing\n",
    "\n",
    "4. Notable Patterns:\n",
    "Human Essay:\n",
    "- Uses more complex noun phrases with prepositions\n",
    "- More varied sentence structures\n",
    "- Natural language patterns\n",
    "\n",
    "Example Essay: \n",
    "- More rigid formatting patterns\n",
    "- Technical/documentation style\n",
    "- Structured headings and lists\n",
    "\n",
    "This suggests the human essay has a more natural writing style while the example essay follows a more structured technical format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building First Chat BOT - PDF Reader\n",
    "The user uploads a PDF of their choice through the user interface.\n",
    "\n",
    "The application parses the PDF using a PDF parsing library and splits the extracted text into manageable chunks.\n",
    "\n",
    "The chunks are converted into vector form, called embeddings.\n",
    "\n",
    "When a user issues a query through the chat interface, the query is also converted into vector form.\n",
    "\n",
    "The vector similarity between the query vector and each of the chunk vectors is calculated.\n",
    "\n",
    "The text corresponding to the top-k most similar vectors are retrieved.\n",
    "\n",
    "The retrieved text is fed along with the query and any other additional instructions to an LLM\n",
    "\n",
    "The LLM uses the given information to generate an answer to the user query.\n",
    "\n",
    "The response is displayed on the user interface. The user can now respond (clarification question, new question, gratitude etc.)\n",
    "\n",
    "The entire conversation history is fed back to the LLM during each turn of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5.0\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "print(pytesseract.get_tesseract_version())\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai langchain gradio unstructured\n",
    "# %pip install langchain-community\n",
    "# %pip install --upgrade pydantic\n",
    "# %pip install pdfminer.six\n",
    "# %pip uninstall pdfminer.six\n",
    "# %pip install pi_heif\n",
    "# %pip install unstructured_inference\n",
    "# %pip install pytesseract\n",
    "# %pip install poppler-utils\n",
    "# %pip install pytesseract\n",
    "\n",
    "# If Tesseract is not in your PATH, include the following line\n",
    "# pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'\n",
    "\n",
    "# LangChain: This very popular framework enables building LLM application pipelines.\n",
    "\n",
    "# Gradio: This library allows you to build LLM-driven user interfaces\n",
    "\n",
    "# Unstructured: This is a PDF parsing suite that supports a variety of methods for extracting text from PDFs.\n",
    "# Sentence-Transformers: This is a library facilitating embeddings generation from texts\n",
    "# Open AI: This API provides access to the GPT* family of models from Open AI.\n",
    "import langchain\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytesseract is not installed. Cannot use the ocr_only partitioning strategy. Falling back to partitioning with another strategy.\n",
      "Falling back to partitioning with hi_res.\n",
      "Failed to get OCRAgent instance: No module named 'unstructured_pytesseract'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/utils/ocr_models/ocr_interface.py:47\u001b[0m, in \u001b[0;36mOCRAgent.get_instance\u001b[0;34m(ocr_agent_module, language)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     loaded_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/utils/ocr_models/tesseract_ocr.py:9\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munstructured_pytesseract\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m PILImage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unstructured_pytesseract'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m UnstructuredPDFLoader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt4_technical_report.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Document]:\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_elements(elements)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:74\u001b[0m, in \u001b[0;36mUnstructuredPDFLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstructured_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/documents/elements.py:581\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 581\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    584\u001b[0m     unique_element_ids: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m call_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_element_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/file_utils/filetype.py:725\u001b[0m, in \u001b[0;36madd_filetype.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 725\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;66;03m# NOTE(robinson) - Attached files have already run through this logic\u001b[39;00m\n\u001b[1;32m    729\u001b[0m         \u001b[38;5;66;03m# in their own partitioning function\u001b[39;00m\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m element\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mattached_to_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/file_utils/filetype.py:683\u001b[0m, in \u001b[0;36madd_metadata.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Element]:\n\u001b[0;32m--> 683\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m     call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m call_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/chunking/dispatch.py:74\u001b[0m, in \u001b[0;36madd_chunking_strategy.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The decorated function is replaced with this one.\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# -- call the partitioning function to get the elements --\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# -- look for a chunking-strategy argument --\u001b[39;00m\n\u001b[1;32m     77\u001b[0m call_args \u001b[38;5;241m=\u001b[39m get_call_args_applying_defaults(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf.py:209\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[0;34m(filename, file, include_page_breaks, strategy, infer_table_structure, ocr_languages, languages, metadata_filename, metadata_last_modified, chunking_strategy, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m exactly_one(filename\u001b[38;5;241m=\u001b[39mfilename, file\u001b[38;5;241m=\u001b[39mfile)\n\u001b[1;32m    207\u001b[0m languages \u001b[38;5;241m=\u001b[39m check_language_args(languages \u001b[38;5;129;01mor\u001b[39;00m [], ocr_languages)\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpartition_pdf_or_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf.py:305\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[0;34m(filename, file, is_image, include_page_breaks, strategy, infer_table_structure, languages, metadata_last_modified, hi_res_model_name, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, starting_page_number, extract_forms, form_extraction_skip_tables, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    304\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m         elements \u001b[38;5;241m=\u001b[39m \u001b[43m_partition_pdf_or_image_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspooled_to_bytes_io_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_page_breaks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_page_breaks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlanguages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_last_modified\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlast_modified\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhi_res_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhi_res_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_text_extractable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_images_in_pdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_image_block_to_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstarting_page_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarting_page_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextract_forms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_forms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m            \u001b[49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_extraction_skip_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m         out_elements \u001b[38;5;241m=\u001b[39m _process_uncategorized_text_elements(elements)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m PartitionStrategy\u001b[38;5;241m.\u001b[39mFAST:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/utils.py:216\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     run_check()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf.py:626\u001b[0m, in \u001b[0;36m_partition_pdf_or_image_local\u001b[0;34m(filename, file, is_image, infer_table_structure, include_page_breaks, languages, ocr_languages, ocr_mode, model_name, hi_res_model_name, pdf_image_dpi, metadata_last_modified, pdf_text_extractable, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, analysis, analyzed_image_output_dir_path, starting_page_number, extract_forms, form_extraction_skip_tables, pdf_hi_res_max_pages, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# NOTE(christine): merged_document_layout = extracted_layout + inferred_layout\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     merged_document_layout \u001b[38;5;241m=\u001b[39m merge_inferred_with_extracted_layout(\n\u001b[1;32m    621\u001b[0m         inferred_document_layout\u001b[38;5;241m=\u001b[39minferred_document_layout,\n\u001b[1;32m    622\u001b[0m         extracted_layout\u001b[38;5;241m=\u001b[39mextracted_layout,\n\u001b[1;32m    623\u001b[0m         hi_res_model_name\u001b[38;5;241m=\u001b[39mhi_res_model_name,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m     final_document_layout \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmerged_document_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextracted_layout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextracted_layout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_image_dpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m     inferred_document_layout \u001b[38;5;241m=\u001b[39m process_data_with_model(\n\u001b[1;32m    639\u001b[0m         file,\n\u001b[1;32m    640\u001b[0m         is_image\u001b[38;5;241m=\u001b[39mis_image,\n\u001b[1;32m    641\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mhi_res_model_name,\n\u001b[1;32m    642\u001b[0m         pdf_image_dpi\u001b[38;5;241m=\u001b[39mpdf_image_dpi,\n\u001b[1;32m    643\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/utils.py:216\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     run_check()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf_image/ocr.py:178\u001b[0m, in \u001b[0;36mprocess_file_with_ocr\u001b[0;34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(filename) \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filename):\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found!\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf_image/ocr.py:165\u001b[0m, in \u001b[0;36mprocess_file_with_ocr\u001b[0;34m(filename, out_layout, extracted_layout, is_image, infer_table_structure, ocr_languages, ocr_mode, pdf_image_dpi, ocr_layout_dumper)\u001b[0m\n\u001b[1;32m    163\u001b[0m     extracted_regions \u001b[38;5;241m=\u001b[39m extracted_layout[i] \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(extracted_layout) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PILImage\u001b[38;5;241m.\u001b[39mopen(image_path) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m--> 165\u001b[0m         merged_page_layout \u001b[38;5;241m=\u001b[39m \u001b[43msupplement_page_layout_with_ocr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpage_layout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_table_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_table_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mocr_languages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mocr_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextracted_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextracted_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_layout_dumper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m         merged_page_layouts\u001b[38;5;241m.\u001b[39mappend(merged_page_layout)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DocumentLayout\u001b[38;5;241m.\u001b[39mfrom_pages(merged_page_layouts)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/utils.py:216\u001b[0m, in \u001b[0;36mrequires_dependencies.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     run_check()\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/pdf_image/ocr.py:201\u001b[0m, in \u001b[0;36msupplement_page_layout_with_ocr\u001b[0;34m(page_layout, image, infer_table_structure, ocr_languages, ocr_mode, extracted_regions, ocr_layout_dumper)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;129m@requires_dependencies\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munstructured_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msupplement_page_layout_with_ocr\u001b[39m(\n\u001b[1;32m    185\u001b[0m     page_layout: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPageLayout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     ocr_layout_dumper: Optional[OCRLayoutDumper] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPageLayout\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Supplement an PageLayout with OCR results depending on OCR mode.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    If mode is \"entire_page\", we get the OCR layout for the entire image and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    with no text and add text from OCR to each element.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     ocr_agent \u001b[38;5;241m=\u001b[39m \u001b[43mOCRAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_languages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ocr_mode \u001b[38;5;241m==\u001b[39m OCRMode\u001b[38;5;241m.\u001b[39mFULL_PAGE\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    203\u001b[0m         ocr_layout \u001b[38;5;241m=\u001b[39m ocr_agent\u001b[38;5;241m.\u001b[39mget_layout_from_image(image)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/utils/ocr_models/ocr_interface.py:34\u001b[0m, in \u001b[0;36mOCRAgent.get_agent\u001b[0;34m(cls, language)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the configured OCRAgent instance.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mThe OCR package used by the agent is determined by the `OCR_AGENT` environment variable.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m ocr_agent_cls_qname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ocr_agent_cls_qname()\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr_agent_cls_qname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/unstructured/partition/utils/ocr_models/ocr_interface.py:52\u001b[0m, in \u001b[0;36mOCRAgent.get_instance\u001b[0;34m(ocr_agent_module, language)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     51\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get OCRAgent instance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not get the OCRAgent instance. Please check the OCR package and the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCR_AGENT environment variable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not get the OCRAgent instance. Please check the OCR package and the OCR_AGENT environment variable."
     ]
    }
   ],
   "source": [
    "loader = UnstructuredPDFLoader('gpt4_technical_report.pdf')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
